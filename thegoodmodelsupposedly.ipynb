{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ingri\\anaconda3\\envs\\mss\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pyautogui\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "import keyboard\n",
    "import cv2 as cv \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mss.tools\n",
    "import time\n",
    "import uuid\n",
    "import keyboard\n",
    "import pyautogui\n",
    "import time\n",
    "import mss.tools\n",
    "import uuid\n",
    "import keyboard\n",
    "from pynput import mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def screenshot():\n",
    "    with mss.mss() as sct:\n",
    "        time.sleep(1)\n",
    "        monitor_info = sct.monitors[0]\n",
    "        top_margin = (monitor_info[\"height\"] // 3) + 50\n",
    "        monitor = {\"top\": monitor_info[\"top\"] + top_margin, \"left\": monitor_info[\"left\"] + 55, \"width\": monitor_info[\"width\"] - 120, \"height\": (monitor_info[\"height\"] * 2 // 3)-105}\n",
    "        output = f\"testimages/{str(uuid.uuid4())}.png\".format(**monitor)\n",
    "        sct_img = sct.grab(monitor)\n",
    "        mss.tools.to_png(sct_img.rgb, sct_img.size, output=output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('model_v2_iris.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_orig = cv.imread(\"DLIngrid\\q/3bd9faf6-2375-4d13-b484-b468c8ae9f02.png\")\n",
    "img_rgb = cv.cvtColor(img_orig, cv.COLOR_BGR2RGB)\n",
    "reshaped_image = np.expand_dims(img_rgb, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 839ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(reshaped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_index = np.argmax(prediction)\n",
    "confidence = prediction[0][action_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.8737693\n"
     ]
    }
   ],
   "source": [
    "action_index = np.argmax(prediction)\n",
    "confidence = prediction[0][action_index]\n",
    "print(action_index)\n",
    "print(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5)\n",
    "while not keyboard.is_pressed(\"space\"):\n",
    "    #test = \n",
    "    image = screenshot()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 1407 files [00:08, 165.94 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "input_folder = './DLIngrid'\n",
    "output_folder = './datasetsingrid'\n",
    " \n",
    "#split the images into 80% training and 20% testing sets\n",
    "splitfolders.ratio(input_folder, output_folder, seed=40, ratio=(0.8, 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "model = ResNet50(include_top=False, weights=\"imagenet\", input_shape=(512, 512, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow.keras.optimizers as optimizers\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94668760/94668760 [==============================] - 10s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model = ResNet50V2(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.output\n",
    "\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "#x = Reshape((1, 1, -1))(x)\n",
    "#x = Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(x)  # Example convolutional layer\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Flatten()(x)\n",
    "#x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "classes = Dense(3, activation='softmax')(x) \n",
    "\n",
    "\n",
    "model = Model(inputs=model.input, outputs=classes)\n",
    "optimizer = optimizers.Adam(learning_rate=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                rotation_range=20,\n",
    "                                width_shift_range=0.1,\n",
    "                                height_shift_range=0.1,\n",
    "                                zoom_range=0.1,\n",
    "                                shear_range=0.2,\n",
    "                                channel_shift_range=0.2,\n",
    "                                brightness_range=(0.8, 1.2),\n",
    "                                #contrast_range=(0.9, 1.1),\n",
    "                                #saturation_range=(0.8, 1.2),\n",
    "                                \n",
    "                                horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1125 images belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 282 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = datagen.flow_from_directory(\"./datasetsingrid/train\", target_size=(224, 224), batch_size=120, class_mode=\"categorical\")\n",
    "val_data = datagen.flow_from_directory(\"./datasetsingrid/val\", target_size=(224, 224), batch_size=120, class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 48s 5s/step - loss: 6.3482 - accuracy: 0.5947 - val_loss: 3.4765 - val_accuracy: 0.7340\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 44s 4s/step - loss: 1.2944 - accuracy: 0.8098 - val_loss: 0.9867 - val_accuracy: 0.7801\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 44s 4s/step - loss: 0.7596 - accuracy: 0.8338 - val_loss: 0.6416 - val_accuracy: 0.7199\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 43s 4s/step - loss: 0.4337 - accuracy: 0.8560 - val_loss: 0.3210 - val_accuracy: 0.9043\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 44s 5s/step - loss: 0.4127 - accuracy: 0.8862 - val_loss: 0.4065 - val_accuracy: 0.8617\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 51s 5s/step - loss: 0.2994 - accuracy: 0.8907 - val_loss: 0.3940 - val_accuracy: 0.8972\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 50s 5s/step - loss: 0.3103 - accuracy: 0.8996 - val_loss: 0.2966 - val_accuracy: 0.8901\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 50s 5s/step - loss: 0.2216 - accuracy: 0.9236 - val_loss: 0.2458 - val_accuracy: 0.9184\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 50s 5s/step - loss: 0.2281 - accuracy: 0.9289 - val_loss: 0.2377 - val_accuracy: 0.9184\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 50s 5s/step - loss: 0.2117 - accuracy: 0.9342 - val_loss: 0.2335 - val_accuracy: 0.9184\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2abfa164dd0>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, epochs=10, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('goodmaybe.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ingri\\anaconda3\\envs\\mss\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('goodmaybe.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsaved = load_model('goodmaybe.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_orig = cv.imread(\"dataset/1c4f5623-a407-4d00-876f-506e4bc5a76b.png\")\n",
    "img_rgb = cv.cvtColor(img_orig, cv.COLOR_BGR2RGB)\n",
    "img = cv2.resize(img_rgb, (224, 224))\n",
    "img_resized = img.astype('float32') / 255.0 \n",
    "reshaped_image = np.expand_dims(img, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n"
     ]
    }
   ],
   "source": [
    "no = modelsaved.predict(reshaped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.99879956\n"
     ]
    }
   ],
   "source": [
    "action_index = np.argmax(no)\n",
    "confidence = no[0][action_index]\n",
    "print(action_index)\n",
    "print(confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9879956e-01, 1.2004360e-03, 3.8443094e-12], dtype=float32)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mss",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
